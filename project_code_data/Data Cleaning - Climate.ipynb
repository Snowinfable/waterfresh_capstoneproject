{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98af1f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f16a5",
   "metadata": {},
   "source": [
    "Pull climate data via API call to create datasets for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26e54204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE. THESE URLS UPDATE frequently, so you will need to update the date at the end of the url to match the current version\n",
    "# find the urls at https://www.ncei.noaa.gov/pub/data/cirs/climdiv/\n",
    "# i.e change https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-pcpncy-v1.0.0-20250306' to\n",
    "# https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-pcpncy-v1.0.0-20250404'\n",
    "# data was originally retrieved for the '20250306' data, but below urls are updated to '20250404' for the github repository\n",
    "\n",
    "url_dict = {'total_precipitation':('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-pcpncy-v1.0.0-20250404','inches'),\n",
    "            'avg_temp': ('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-tmpccy-v1.0.0-20250404','F'),\n",
    "            'max_temp': ('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-tmaxcy-v1.0.0-20250404','F'),\n",
    "            'min_temp': ('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-tmincy-v1.0.0-20250404','F'),\n",
    "            'cool_deg_days': ('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-cddccy-v1.0.0-20250404', 'count'), \n",
    "            'heat_deg_days': ('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-hddccy-v1.0.0-20250404', 'count')\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21791075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the NOAA site, the state codes do not match state FIPS codes. Below fixes this.\n",
    "# https://www.bls.gov/respondents/mwr/electronic-data-interchange/appendix-d-usps-state-abbreviations-and-fips-codes.htm\n",
    "state_code_dict={'01':'01', '02':'04', '03':'05', '04':'06', '05':'08', '06':'09', '07':'10',\n",
    "                '08':'12', '09':'13', '10':'16', '11':'17', '12':'18', '13':'19', '14':'20',\n",
    "                '15':'21', '16':'22', '17': '23', '18':'24', '19':'25', '20':'26', '21':'27', \n",
    "                '22':'28', '23':'29', '24':'30', '25':'31', '26':'32', '27':'33', '28':'34', \n",
    "                '29':'35', '30':'36', '31':'37', '32':'38', '33':'39', '34':'40', '35':'41',\n",
    "                '36':'42', '37':'44', '38':'45', '39':'46', '40':'47', '41':'48', '42':'49',\n",
    "                '43':'50', '44':'51', '45':'53', '46':'54', '47':'55', '48':'56', '49':'15',\n",
    "                '50':'02'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2e13cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = {}\n",
    "for category, url in url_dict.items():\n",
    "    response = requests.get(url[0])\n",
    "    lines = response.text.splitlines()\n",
    "    line_list = []\n",
    "    columns = ['measure', 'unit', 'state', 'county', 'county_fips', 'year', 'jan', 'feb', \n",
    "               'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "    for line in lines: \n",
    "        line = line.strip()\n",
    "        fields = line.split()\n",
    "        months = [float(x) for x in fields[1:]]\n",
    "        id_string = fields[0]\n",
    "        \n",
    "        state = id_string[:2]\n",
    "        state_fip = state_code_dict[state]\n",
    "        county = id_string[2:5]\n",
    "        county_fips = state_fip + county\n",
    "        year = int(id_string[7:])\n",
    "        \n",
    "        prefix = [category, url[1], state, county, county_fips, year]\n",
    "        line_list.append(prefix + months)\n",
    "    \n",
    "    df = pd.DataFrame(line_list, columns = columns)\n",
    "    all_dfs[category] = df\n",
    "\n",
    "total_precip = all_dfs['total_precipitation']\n",
    "max_temp = all_dfs['max_temp']\n",
    "min_temp = all_dfs['min_temp']\n",
    "avg_temp = all_dfs['avg_temp']\n",
    "cool = all_dfs['cool_deg_days']\n",
    "hot = all_dfs['heat_deg_days']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d85c1f",
   "metadata": {},
   "source": [
    "Calculate means and slopes for every month for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f6c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = {}\n",
    "column_months = ['jan_mean', 'feb_mean', 'mar_mean', 'apr_mean', 'may_mean', 'jun_mean', 'jul_mean', 'aug_mean', \n",
    "                 'sep_mean', 'oct_mean', 'nov_mean', 'dec_mean', 'jan_slope', 'feb_slope', 'mar_slope', 'apr_slope', \n",
    "                 'may_slope', 'jun_slope', 'jul_slope', 'aug_slope', 'sep_slope', 'oct_slope', 'nov_slope', 'dec_slope'\n",
    "                ]\n",
    "\n",
    "for df in [total_precip, max_temp, min_temp, avg_temp, cool, hot]:\n",
    "    \n",
    "    measure = df.loc[0, 'measure']\n",
    "    unit = df.loc[0, 'unit']\n",
    "    \n",
    "    column_months_spec = [x + '_' + measure for x in column_months]\n",
    "    cleaned_columns = ['measure', 'unit','county_fips'] + column_months_spec    \n",
    "    \n",
    "    #filter for the years 2000-2020\n",
    "    df = df[(df['year']>=2000) & (df['year']<2021)]\n",
    "    \n",
    "    #drop some columns. Then groupby county_fips.\n",
    "    dropped = df.drop(['measure', 'unit', 'state', 'county', 'year'], axis = 1)\n",
    "    grouped = dropped.groupby(['county_fips'])\n",
    "    means_df = grouped.mean()\n",
    "    \n",
    "    groups = grouped.groups.keys()\n",
    "    measure_dict = {}\n",
    "    for g in groups:\n",
    "        county_df = grouped.get_group(g).reset_index(drop = True)\n",
    "        county = county_df.loc[0, 'county_fips']\n",
    "        \n",
    "        #pull mean data\n",
    "        month_means = list(means_df.loc[g])\n",
    "        \n",
    "        #find slopes\n",
    "        year_count = len(county_df)\n",
    "        month_slopes = []\n",
    "        for month in county_df.columns[1:]:\n",
    "            data = county_df[month]\n",
    "            x = np.array(list(range(year_count))).reshape(-1,1)\n",
    "            y = np.array(data).reshape(-1,1)\n",
    "            linreg = LinearRegression().fit(x, y)            \n",
    "            slope = linreg.coef_[0][0]\n",
    "            month_slopes.append(slope)\n",
    "        \n",
    "        #dict with list data for each county\n",
    "        full_data = [measure, unit, county] + month_means + month_slopes\n",
    "        measure_dict[county] = full_data\n",
    "    \n",
    "    #create df for each measure (avg temp, precipitation, etc)\n",
    "    measure_df = pd.DataFrame.from_dict(measure_dict, orient = 'index')\n",
    "    measure_df.columns = cleaned_columns\n",
    "    cleaned_dfs[measure] = measure_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee20b6",
   "metadata": {},
   "source": [
    "merge all dataframes and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98341574",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = list(cleaned_dfs.values())\n",
    "base_df = all_dfs[0]\n",
    "base_df = base_df.drop(['measure', 'unit'], axis = 1)\n",
    "merge_dfs = all_dfs[1:]\n",
    "\n",
    "for df in merge_dfs:\n",
    "    df = df.drop(['measure', 'unit'], axis = 1)\n",
    "    base_df = base_df.merge(df,how = 'left', on='county_fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d706e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.to_csv('merge_data/climate_all_data_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3bc5f",
   "metadata": {},
   "source": [
    "remove heat and cool days and export that version too. This version is used for modeling since heat/cool days has too much missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75eca312",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = list(cleaned_dfs.values())[:-2]\n",
    "base_df = all_dfs[0]\n",
    "base_df = base_df.drop(['measure', 'unit'], axis = 1)\n",
    "merge_dfs = all_dfs[1:]\n",
    "\n",
    "for df in merge_dfs:\n",
    "    df = df.drop(['measure', 'unit'], axis = 1)\n",
    "    base_df = base_df.merge(df,how = 'left', on='county_fips')\n",
    "    \n",
    "base_df.to_csv('merge_data/climate_all_data_clean_without_heat-cool-days.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7009c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
